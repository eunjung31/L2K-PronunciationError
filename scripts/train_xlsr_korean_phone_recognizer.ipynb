{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "503c5fa1",
      "metadata": {
        "id": "503c5fa1"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f91ca4",
      "metadata": {
        "id": "c8f91ca4"
      },
      "outputs": [],
      "source": [
        "!export HF_DATASETS_CACHE='/path/to/save/cache'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fd79f6",
      "metadata": {
        "id": "e7fd79f6"
      },
      "outputs": [],
      "source": [
        "repo_name = \"wav2vec2-xls-r-300m_phone-mfa_korean\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e4c4615",
      "metadata": {
        "id": "9e4c4615"
      },
      "source": [
        "### Import related libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaee7557",
      "metadata": {
        "id": "eaee7557"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import jiwer\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "import transformers\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2PhonemeCTCTokenizer, Wav2Vec2ForCTC, \\\n",
        "TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d6e90b",
      "metadata": {
        "id": "59d6e90b"
      },
      "source": [
        "### Data Preparation in JSON Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfeea340",
      "metadata": {
        "id": "bfeea340"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def prepare_json_format(data_name, data_path):\n",
        "    w = open(data_name, 'w')\n",
        "    wav_list = sorted(glob.glob(data_path))\n",
        "    for i in tqdm(range(len(wav_list)), ncols=40):\n",
        "        wav = wav_list[i]\n",
        "        fname = wav.rsplit('/',1)[-1].rsplit('.',1)[0]\n",
        "        abs_path = wav\n",
        "        text = open(wav.rsplit('.',1)[0] + '.mfa.txt', 'r').readlines()[0].strip()\n",
        "        json_line = '{\"fname\":\"%s\", \"path\":\"%s\", \"sampling_rate\":16000, \"text\":\"%s\"}' % (fname, abs_path, text)\n",
        "        w.write(json_line + \"\\n\")\n",
        "    w.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17044833",
      "metadata": {
        "id": "17044833"
      },
      "outputs": [],
      "source": [
        "tr_data_name = './path/to/data/train.json'\n",
        "te_data_name = './path/to/data/test.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa88764f",
      "metadata": {
        "id": "aa88764f"
      },
      "outputs": [],
      "source": [
        "tr_data_path = \"/path/to/data/train/*.wav\"\n",
        "te_data_path = \"/path/to/data/test/*.wav\"\n",
        "\n",
        "prepare_json_format(tr_data_name, tr_data_path)\n",
        "prepare_json_format(te_data_name, te_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31afcc5",
      "metadata": {
        "id": "b31afcc5"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset('json', data_files={'train':tr_data_name, 'test':te_data_name},\n",
        "                  cache_dir='/path/to/save/cache')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbcb039",
      "metadata": {
        "scrolled": true,
        "id": "3cbcb039"
      },
      "outputs": [],
      "source": [
        "from datasets import ClassLabel\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(ds['train'].remove_columns(['fname','path', 'sampling_rate']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ff203e",
      "metadata": {
        "id": "59ff203e"
      },
      "outputs": [],
      "source": [
        "def extract_all_chars(batch):\n",
        "    all_text = \" \".join(batch['text'])\n",
        "    # vocab = list(set(all_text))\n",
        "    vocab = list(set(all_text.split()))\n",
        "    return {\"vocab\":[vocab], \"all_text\":[all_text]}\n",
        "\n",
        "vocabs = ds.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=ds.column_names['train'])\n",
        "# print(list(set(vocabs['train']['vocab'][0])))\n",
        "vocab_list = list(set(vocabs['train']['vocab'][0]) | set(vocabs['test']['vocab'][0]))\n",
        "vocab_dict = {v:k for k,v in enumerate(sorted(vocab_list))}\n",
        "vocab_dict[' '] = len(vocab_dict)\n",
        "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
        "del vocab_dict[\" \"]\n",
        "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
        "vocab_dict[\"[PAD]\"] = len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce1fa37",
      "metadata": {
        "id": "dce1fa37"
      },
      "outputs": [],
      "source": [
        "vocab_name = \"./vocab/vocab.json\"\n",
        "\n",
        "with open(vocab_name, 'w') as vocab_file:\n",
        "    json.dump(vocab_dict, vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c3b893",
      "metadata": {
        "id": "65c3b893"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2PhonemeCTCTokenizer\n",
        "tokenizer = Wav2Vec2PhonemeCTCTokenizer.from_pretrained(\"./vocab/\", pad_token=\"[PAD]\", unk_token=\"[UNK]\",\n",
        "                                                        phone_delimiter_token=\"|\",\n",
        "                                                        do_phonemize=False,\n",
        "                                                        cache_dir='/path/to/save/cache')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e143f948",
      "metadata": {
        "id": "e143f948"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub(repo_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb725e5",
      "metadata": {
        "id": "efb725e5"
      },
      "outputs": [],
      "source": [
        "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True, cache_dir='/data2/excalibur12/.cache/huggingface/datasets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad382b3",
      "metadata": {
        "id": "7ad382b3"
      },
      "outputs": [],
      "source": [
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74683ae3",
      "metadata": {
        "id": "74683ae3"
      },
      "outputs": [],
      "source": [
        "def prep_dataset(batch):\n",
        "    audio = batch['path']\n",
        "    batch['input_values'] = processor(librosa.load(audio, sr=16000)[0], sampling_rate=batch['sampling_rate']).input_values[0]\n",
        "    batch['input_length'] = len(batch['input_values'])\n",
        "    \n",
        "    with processor.as_target_processor():\n",
        "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
        "\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "038fb93c",
      "metadata": {
        "scrolled": false,
        "id": "038fb93c"
      },
      "outputs": [],
      "source": [
        "ds = ds.map(prep_dataset, remove_columns=ds.column_names['train'], num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e626f0",
      "metadata": {
        "id": "f3e626f0"
      },
      "outputs": [],
      "source": [
        "max_input_length_in_sec = 12.0\n",
        "ds['train'] = ds['train'].filter(lambda x: x < max_input_length_in_sec * processor.feature_extractor.sampling_rate, input_columns=[\"input_length\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85e4dff7",
      "metadata": {
        "id": "85e4dff7"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_length_labels: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    pad_to_multiple_of_labels: Optional[int] = None\n",
        "    \n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        \n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                max_length=self.max_length_labels,\n",
        "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "        \n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        \n",
        "        batch['labels'] = labels\n",
        "        \n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79230bd",
      "metadata": {
        "id": "d79230bd"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2449f0dd",
      "metadata": {
        "id": "2449f0dd"
      },
      "outputs": [],
      "source": [
        "wer_metric = load_metric('wer', cache_dir='/path/to/save/cache')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f486a8cc",
      "metadata": {
        "id": "f486a8cc"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "    \n",
        "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    \n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    \n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "    \n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "    \n",
        "    return {\"PER\": wer}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6101f608",
      "metadata": {
        "id": "6101f608"
      },
      "outputs": [],
      "source": [
        "model = Wav2Vec2ForCTC.from_pretrained(\n",
        "    'facebook/wav2vec2-xls-r-300m',\n",
        "    ctc_loss_reduction='mean',\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    vocab_size=len(processor.tokenizer),\n",
        "    cache_dir='/path/to/save/cache'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51de8ed4",
      "metadata": {
        "id": "51de8ed4"
      },
      "outputs": [],
      "source": [
        "model.freeze_feature_encoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364d2d7c",
      "metadata": {
        "id": "364d2d7c"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=repo_name,\n",
        "    group_by_length=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    # evaluation_strategy=\"steps\", ## comment out when only training\n",
        "    evaluation_strategy=\"epoch\",  ## Choose either \"steps\" or \"epoch\"\n",
        "    # logging_strategy=\"steps\",\n",
        "    logging_strategy=\"epoch\",  ## Choose either \"steps\" or \"epoch\"\n",
        "    num_train_epochs=20,\n",
        "    fp16=True,\n",
        "    gradient_checkpointing=False,\n",
        "    # save_strategy=\"steps\",\n",
        "    save_strategy=\"epoch\",\n",
        "    # save_steps=1000,  ## Only when save_strategy is \"step\"\n",
        "    # eval_steps=1000, ## Only when save_strategy is \"step\" ## comment out when only training\n",
        "    # logging_steps=1000, ## Only when save_strategy is \"step\"\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.005,\n",
        "    warmup_ratio=0.2,\n",
        "    # warmup_steps=750, ##5000,\n",
        "    save_total_limit=10,\n",
        "    load_best_model_at_end=True,\n",
        "    # no_cuda=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a061ffc",
      "metadata": {
        "id": "2a061ffc"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(Trainer):\n",
        "    def log(self, logs: Dict[str, float]) -> None:\n",
        "        logs['learning_rate'] = self._get_learning_rate()\n",
        "        super().log(logs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19328437",
      "metadata": {
        "id": "19328437"
      },
      "outputs": [],
      "source": [
        "trainer = MyTrainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=ds['train'],\n",
        "    eval_dataset=ds['test'], ## comment out when only training\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f672fe",
      "metadata": {
        "scrolled": true,
        "id": "36f672fe"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c5f147",
      "metadata": {
        "id": "b4c5f147"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c395598",
      "metadata": {
        "id": "7c395598"
      },
      "outputs": [],
      "source": [
        "checkpoint_step_num = 20250\n",
        "tokenizer.save_pretrained('/path/to/tokenizer/model/{}/checkpoint-{}'.format(repo_name, checkpoint_step_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00c0bf0a",
      "metadata": {
        "id": "00c0bf0a"
      },
      "outputs": [],
      "source": [
        "tokenizer.push_to_hub()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}